{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG16.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPTt0CUjE7SPFzuLjP1spo2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Load Data"],"metadata":{"id":"D-26lgDaU2wE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AnQYejWHUfOp"},"outputs":[],"source":["! pip install -q kaggle"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"uR4DOvjgUmtD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/Kuliah/TKC/Code\""],"metadata":{"id":"l44TCLI5U6o9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Kuliah/TKC/Code"],"metadata":{"id":"I0jXRTjMVNDr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls"],"metadata":{"id":"UAkU-p4kVQA0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!kaggle datasets download -d ashishjangra27/face-mask-12k-images-dataset"],"metadata":{"id":"20Qfsc87VQXM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#1.1 Unzip data\n","from zipfile import ZipFile\n","file_name = \"face-mask-12k-images-dataset.zip\"\n","\n","with ZipFile(file_name,'r') as zip :\n","  zip.extractall()\n","  print('Berhasil')"],"metadata":{"id":"CaCHMGAeVuIP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Define a path\n","base_dir = '/content/drive/MyDrive/Kuliah/TKC/Code/Face Mask Dataset'\n","train_dir = os.path.join(base_dir, 'Train')\n","validation_dir = os.path.join(base_dir, 'Validation')\n","test_dir = os.path.join(base_dir, 'Test')\n","\n","\n","train_with_mask_dir = os.path.join(train_dir, 'WithMask')\n","train_without_mask_dir = os.path.join(train_dir, 'WithoutMask')\n","\n","validation_with_mask_dir = os.path.join(validation_dir, 'WithMask')\n","validation_without_mask_dir = os.path.join(validation_dir, 'WithoutMask')\n","\n","test_with_mask_dir = os.path.join(test_dir, 'WithMask')\n","test_without_mask_dir = os.path.join(test_dir, 'WithoutMask')"],"metadata":{"id":"4Lqn3i4_W9sc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Train : ')\n","\n","print('Train with_mask : ', len(os.listdir(train_with_mask_dir)))\n","print('Train without_mask : ', len(os.listdir(train_without_mask_dir)))\n","print(\"\"*2)\n","print('Validation : ')\n","\n","print('Validationn with_mask : ', len(os.listdir(validation_with_mask_dir)))\n","print('Validation without_mask : ', len(os.listdir(validation_without_mask_dir)))\n","print(\"\"*2)\n","print('Test : ')\n","\n","print('Test with_mask : ', len(os.listdir(test_with_mask_dir)))\n","print('Test without_mask : ', len(os.listdir(test_without_mask_dir)))"],"metadata":{"id":"yF_Z2guJfBYn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Preprocessing"],"metadata":{"id":"xdu3aISLfIYu"}},{"cell_type":"code","source":["height = 100\n","width = 100\n","batch_size = 32"],"metadata":{"id":"3GOAJ-6vfEQ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install keras"],"metadata":{"id":"4la-1aXOfPG2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import keras_preprocessing\n","from keras_preprocessing import image\n","from keras_preprocessing.image import ImageDataGenerator"],"metadata":{"id":"PW4xkpYbfQTU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TRAINING_DIR = \"/content/drive/MyDrive/Kuliah/TKC/Code/Face Mask Dataset/Train\"\n","VALIDATION_DIR = \"/content/drive/MyDrive/Kuliah/TKC/Code/Face Mask Dataset/Validation\"\n","TEST_DIR = \"/content/drive/MyDrive/Kuliah/TKC/Code/Face Mask Dataset/Test\""],"metadata":{"id":"AYCkWDc-fR3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generator_datagen = ImageDataGenerator(\n","    rescale = 1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","val_gen = ImageDataGenerator(rescale = 1./255)\n","\n","train_generator = generator_datagen.flow_from_directory(\n","    TRAINING_DIR,\n","    target_size=(height, width),\n","    class_mode='categorical',\n","    color_mode=\"rgb\",\n","    shuffle=True,\n","    batch_size=batch_size\n",")\n","\n","validation_generator = val_gen.flow_from_directory(\n","    VALIDATION_DIR,\n","    target_size=(height,width),\n","    class_mode='categorical',\n","    color_mode=\"rgb\",\n","    shuffle=False,\n","    batch_size=batch_size\n",")\n","\n","test_generator = val_gen.flow_from_directory(\n","    TEST_DIR,\n","    target_size=(height,width),\n","    class_mode='categorical',\n","    color_mode=\"rgb\",\n","    shuffle=False,\n","    batch_size=batch_size\n",")"],"metadata":{"id":"BbVblIrTfZ75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#tampilkan Data Generator\n","import matplotlib.pyplot as plt\n","plt.figure(figsize = (14, 8))\n","for i in range(30):\n","    plt.subplot(5, 10, i + 1)\n","    \n","    for X, y in train_generator:\n","\n","        plt.imshow(X[0])\n","        plt.axis(\"off\")\n","        break\n","        \n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"RWORpw9GfcAc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Modelling"],"metadata":{"id":"KZ7YTQrIff-R"}},{"cell_type":"code","source":["# IMPORT SEMUA PAKET YANG ANDA PERLUKAN UNTUK MENDEFINISIKAN MODEL DISINI\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import InputLayer, Dense, Conv2D, MaxPool2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"],"metadata":{"id":"G-hs8TGffeEK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model = VGG16(input_shape = (100,100,3),\n","                           include_top = False,\n","                           weights = \"imagenet\")\n","base_model.trainable = False"],"metadata":{"id":"cY-tH09Kfh_Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# i add some of layer and setting dropout more big to avoid Overffiting in my model\n","print('Adding new layers')\n","x = base_model.get_layer(index = -1).output\n","x = Flatten()(base_model.output)\n","x = Dense(256,activation = \"relu\")(x)\n","x = BatchNormalization()(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64,activation = \"relu\")(x)\n","x = BatchNormalization()(x)\n","x = Dropout(0.5)(x)\n","x = Dense(2, activation='softmax')(x) \n","print('Finished')"],"metadata":{"id":"aPLwqyqrfknv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Model(base_model.input, x)\n","model.summary()\n","\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])"],"metadata":{"id":"9SXRH4NNfmMB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# setting Callback so we can save the best model in format h5 and i save it in my drive\n","callbacks = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')        \n","direc = '/content/drive/MyDrive/Kuliah/TKC/Code/Model_VGG16.h5'\n","best_model = ModelCheckpoint(direc, monitor='val_acc', verbose = 1, save_best_only = True)"],"metadata":{"id":"1GVL9rdIfoWf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["H = model.fit(train_generator,\n","                    epochs=100,\n","                    steps_per_epoch=93,  # images = batch_size * steps\n","                    verbose=1,\n","                    validation_data=validation_generator,\n","                    callbacks=[callbacks, best_model])"],"metadata":{"id":"R5Xv2HO4fvRh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Result"],"metadata":{"id":"gmLnXu92lpry"}},{"cell_type":"code","source":["import json\n","from tensorflow.keras.models import load_model\n","\n","target_dir = '/content/drive/MyDrive/Kuliah/TKC/Code'\n","model_saved = load_model(target_dir + '/Model_VGG16.h5')"],"metadata":{"id":"zGsYAODrfwx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_score = model_saved.evaluate_generator(validation_generator, validation_generator.batch_size)\n","print(\"[INFO] accuracy: {:.2f}%\".format(test_score[1] * 100)) \n","print(\"[INFO] Loss: \",test_score[0])"],"metadata":{"id":"3CUfw-yglvDd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(H.history.keys())"],"metadata":{"id":"i8mYjTDrl4OJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","acc = H.history['acc']\n","val_acc = H.history['val_acc']\n","loss = H.history['loss']\n","val_loss = H.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'bo', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","\n","plt.figure()\n","    \n","plt.plot(epochs, loss, 'bo', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"4TXq6FGCl5vb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Print Classification Report\n","#Print the Target names\n","\n","target_names = []\n","\n","for key in train_generator.class_indices:\n","    target_names.append(key)\n","print(target_names)"],"metadata":{"id":"e_ETdQC9l6q6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Classification Report\n","import numpy as np\n","from sklearn.metrics import classification_report\n","Y_pred = model.predict_generator(test_generator)\n","y_pred = np.argmax(Y_pred, axis=1)\n","\n","print('Classification Report')\n","print(classification_report(test_generator.classes, y_pred, target_names=target_names))"],"metadata":{"id":"imGw6Lwzl8NN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(H.history.keys())"],"metadata":{"id":"ieDCDiCwl9Jh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_datagen = ImageDataGenerator()\n","\n","test_generator  = test_datagen.flow_from_directory(test_dir,\n","                                          class_mode=None,\n","                                          shuffle=False,\n","                                          target_size=(150, 150))"],"metadata":{"id":"oUrCrxufl-ev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","Cmatrix_test = confusion_matrix(test_generator.classes, y_pred)\n","class_names = test_generator.class_indices\n","\n","plt.figure(figsize = (15,12))\n","ax = plt.subplot()\n","sns.set(font_scale=2.0) # Adjust to fit\n","sns.heatmap(Cmatrix_test,annot=True, fmt='',ax=ax, cmap=plt.cm.Reds)\n","\n","# labels, title and ticks\n","label_font = {'size':'15'}  # Adjust to fit\n","ax.set_xlabel('Predicted labels', fontdict=label_font)\n","ax.set_ylabel('True labels', fontdict=label_font) \n","\n","title_font = {'size':'18'}  # Adjust to fit\n","ax.set_title('Confusion Matrix', fontdict=title_font)\n","\n","ax.tick_params(axis='both', which='major', labelsize=15)  # Adjust to fit\n","ax.xaxis.set_ticklabels(class_names)   \n","ax.yaxis.set_ticklabels(class_names)\n","plt.title('Confusion Matrix Test',fontsize=14)\n","plt.show()"],"metadata":{"id":"zuMfCE4QmAZS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Predict"],"metadata":{"id":"PKONRoFsmCdi"}},{"cell_type":"code","source":["import json\n","from tensorflow.keras.models import load_model\n","\n","target_dir = '/content/drive/MyDrive/Kuliah/TKC/Code'\n","model_saved = load_model(target_dir + '/Model_VGG16.h5')"],"metadata":{"id":"Ou2_kYNAmBOU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","import time\n","\n","def pred_img(img_path):\n","    img = load_img(img_path, target_size=(100,100))\n","    img = img_to_array(img)\n","    img = np.expand_dims(img, axis=0)\n","\n","    start_pred_time = time.time()\n","\n","    pred_result = model_saved.predict(img)\n","\n","    end_pred_time = time.time()\n","\n","    pred_value = np.argmax(pred_result[0])\n","    #pred_label = list(label_dict.keys())[list(label_dict.values()).index(pred_value)]\n","    pred_label = 'WithMask' if pred_value == 0 else 'WithoutMask' \n","    confidence_percent = np.max(pred_result[0]) * 100\n","    pred_time = end_pred_time - start_pred_time\n","\n","    return pred_label, confidence_percent, pred_time"],"metadata":{"id":"8PHbfS8MmHwX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wmask_name_dir = [os.path.join(test_with_mask_dir, fname) for fname in os.listdir(test_with_mask_dir)[15:20]]\n","wout_name_dir = [os.path.join(test_without_mask_dir, fname) for fname in os.listdir(test_without_mask_dir)[25:30]]\n","\n","wmask_wout_dir = wmask_name_dir + wout_name_dir"],"metadata":{"id":"qNn3c6o-mS9N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import cv2\n","nrows = 3\n","ncols = 5\n","\n","fig = plt.gcf()\n","fig.set_size_inches(ncols * 4, nrows * 4)\n","\n","for i, img_path in enumerate(wmask_wout_dir ):\n","    plt.subplot(nrows, ncols, i + 1)\n","    plt.subplots_adjust(hspace=1.5)\n","\n","    img = cv2.imread(img_path)\n","    img = cv2.resize(img, (100,100))\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","    true_label = img_path.split(os.path.sep)[-2]\n","    pred_result = pred_img(img_path)\n","    pred_label = pred_result[0]\n","    confidence_percent = pred_result[1]\n","    pred_time = pred_result[2]\n","\n","    plt.title(f\"True Label: {true_label}\\nPred Label: {pred_label}\\nAkurasi: {confidence_percent:.2f}%\\nTime: {pred_time:.4f}s\", y=1.15)\n","    plt.imshow(img)\n","\n","plt.show()"],"metadata":{"id":"WzlGR-LymWcu"},"execution_count":null,"outputs":[]}]}